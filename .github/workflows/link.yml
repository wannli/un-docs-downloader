name: Link

on:
  push:
    paths:
      - 'data/detected/**'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: link-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  link:
    name: Link
    runs-on: ubuntu-latest
    steps:
      - name: Log workflow start
        run: |
          echo "::group::Workflow Metadata"
          echo "workflow_name=link"
          echo "run_id=${{ github.run_id }}"
          echo "run_number=${{ github.run_number }}"
          echo "event_name=${{ github.event_name }}"
          echo "ref=${{ github.ref_name }}"
          echo "started_at=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "::endgroup::"
          echo "WORKFLOW_START=$(date +%s)" >> $GITHUB_ENV

      - name: Checkout
        run: echo "STEP_START=$(date +%s)" >> $GITHUB_ENV

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Log checkout duration
        run: |
          DURATION=$(($(date +%s) - $STEP_START))
          echo "::notice::step=checkout duration_seconds=$DURATION"

      - name: Set up Python
        run: echo "STEP_START=$(date +%s)" >> $GITHUB_ENV

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Log Python setup duration
        run: |
          DURATION=$(($(date +%s) - $STEP_START))
          echo "::notice::step=setup_python duration_seconds=$DURATION"

      - name: Install dependencies
        run: |
          STEP_START=$(date +%s)
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          pip install -e .
          DURATION=$(($(date +%s) - $STEP_START))
          echo "::notice::step=install_dependencies duration_seconds=$DURATION"

      - name: Ensure branch checkout
        run: git checkout -B "${GITHUB_REF_NAME}"

      - name: Run document linking
        run: |
          STEP_START=$(date +%s)
          python -c "
          import sys
          import json
          import time
          from pathlib import Path
          sys.path.insert(0, 'src')
          from mandate_pipeline.linking import derive_resolution_origin

          total_start = time.time()
          metrics = {'step': 'link'}

          print('::group::Load Documents')
          load_start = time.time()
          detected_dir = Path('data/detected')
          linked_dir = Path('data/linked')
          linked_dir.mkdir(parents=True, exist_ok=True)

          documents = []
          if detected_dir.exists():
              for detected_file in detected_dir.glob('*.json'):
                  with open(detected_file) as f:
                      doc = json.load(f)
                      documents.append(doc)

          load_duration = time.time() - load_start
          metrics['documents_loaded'] = len(documents)
          metrics['load_duration_seconds'] = round(load_duration, 2)
          print(f'Loaded {len(documents)} detected documents in {load_duration:.2f}s')
          print('::endgroup::')

          print('::group::Create Linkages')
          link_start = time.time()
          linked_documents = []
          doc_type_counts = {'resolution': 0, 'proposal': 0, 'other': 0}

          for doc in documents:
              symbol = doc['symbol']
              doc_type = 'resolution' if 'RES' in symbol else 'proposal' if 'L.' in symbol else 'other'
              doc_type_counts[doc_type] += 1

              linked_doc = {
                  'symbol': symbol,
                  'doc_type': doc_type,
                  'origin': derive_resolution_origin({
                      'symbol': symbol,
                      'linked_proposal_symbols': []
                  }),
                  'linked_proposals': [],
                  'linked_resolutions': [],
                  'signal_summary': doc.get('signal_summary', {}),
                  'signals': doc.get('signals', {})
              }

              linked_documents.append(linked_doc)

              output_file = linked_dir / f'{Path(symbol.replace(\"/\", \"_\")).stem}.json'
              with open(output_file, 'w') as f:
                  json.dump(linked_doc, f, indent=2)

          link_duration = time.time() - link_start
          metrics['link_duration_seconds'] = round(link_duration, 2)
          print(f'Created linkages in {link_duration:.2f}s')
          print('::endgroup::')

          print('::group::Write Index')
          index_start = time.time()
          linkage_index = {
              'documents': linked_documents,
              'stats': {
                  'total_documents': len(linked_documents),
                  'resolutions': doc_type_counts['resolution'],
                  'proposals': doc_type_counts['proposal'],
                  'other': doc_type_counts['other'],
                  'linked_pairs': 0
              }
          }

          with open(linked_dir / 'index.json', 'w') as f:
              json.dump(linkage_index, f, indent=2)

          index_duration = time.time() - index_start
          metrics['index_duration_seconds'] = round(index_duration, 2)
          print(f'Wrote index in {index_duration:.2f}s')
          print('::endgroup::')

          metrics['documents_linked'] = len(linked_documents)
          metrics['resolutions'] = doc_type_counts['resolution']
          metrics['proposals'] = doc_type_counts['proposal']
          metrics['other'] = doc_type_counts['other']
          metrics['total_duration_seconds'] = round(time.time() - total_start, 2)

          # Write metrics to file for shell to read
          with open('/tmp/link_metrics.txt', 'w') as f:
              f.write(f'documents_loaded={metrics[\"documents_loaded\"]}\n')
              f.write(f'documents_linked={len(linked_documents)}\n')
              f.write(f'resolutions={doc_type_counts[\"resolution\"]}\n')
              f.write(f'proposals={doc_type_counts[\"proposal\"]}\n')
              f.write(f'other={doc_type_counts[\"other\"]}\n')

          print('::group::Linking Metrics')
          for key, value in metrics.items():
              print(f'{key}={value}')
          print('::endgroup::')
          "

          # Read metrics into env vars
          if [ -f /tmp/link_metrics.txt ]; then
            while IFS='=' read -r key value; do
              echo "LINK_${key^^}=$value" >> $GITHUB_ENV
            done < /tmp/link_metrics.txt
          fi

          DURATION=$(($(date +%s) - $STEP_START))
          echo "LINK_STEP_DURATION=$DURATION" >> $GITHUB_ENV
          echo "::notice::step=link duration_seconds=$DURATION"

      - name: Commit linking results
        run: |
          STEP_START=$(date +%s)
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/linked/

          LINKED_SIZE=$(du -sh data/linked 2>/dev/null | cut -f1 || echo "0")
          LINKED_COUNT=$(ls -1 data/linked/*.json 2>/dev/null | wc -l || echo 0)
          echo "LINKED_SIZE=$LINKED_SIZE" >> $GITHUB_ENV
          echo "LINKED_COUNT=$LINKED_COUNT" >> $GITHUB_ENV

          if git diff --staged --quiet; then
            echo "COMMIT_RESULT=no_changes" >> $GITHUB_ENV
            echo "::notice::step=commit result=no_changes"
          else
            FILES_CHANGED=$(git diff --staged --numstat | wc -l)
            echo "COMMIT_RESULT=pushed" >> $GITHUB_ENV
            echo "FILES_CHANGED=$FILES_CHANGED" >> $GITHUB_ENV
            git commit -m "chore: link related documents"
            git pull --rebase origin "${GITHUB_REF_NAME}" || true
            git push
            echo "::notice::step=commit result=pushed files_changed=$FILES_CHANGED"
          fi
          DURATION=$(($(date +%s) - $STEP_START))
          echo "COMMIT_DURATION=$DURATION" >> $GITHUB_ENV

      - name: Write workflow summary
        if: always()
        run: |
          TOTAL_DURATION=$(($(date +%s) - $WORKFLOW_START))

          cat >> $GITHUB_STEP_SUMMARY << 'SUMMARY_EOF'
          ## üîó Link Workflow Summary

          **Run:** #${{ github.run_number }} | **Trigger:** `${{ github.event_name }}`
          SUMMARY_EOF

          cat >> $GITHUB_STEP_SUMMARY << EOF

          ### ‚ú® What Was Linked

          | Documents Processed | **${LINK_DOCUMENTS_LINKED:-0}** |
          |---------------------|--------------------------------|

          ### üìÅ Document Types Found

          | Type | Count |
          |------|-------|
          | üìú Resolutions | **${LINK_RESOLUTIONS:-0}** |
          | üìù Proposals   | **${LINK_PROPOSALS:-0}** |
          | üìÑ Other       | ${LINK_OTHER:-0} |

          ### üìä Current Totals

          | Metric | Count |
          |--------|-------|
          | Total Linked Files | ${LINKED_COUNT:-0} |
          | Data Size | ${LINKED_SIZE:-N/A} |

          ### üì§ Result

          | Outcome | Status |
          |---------|--------|
          | Commit | ${COMMIT_RESULT:-N/A} |
          | Files Changed | ${FILES_CHANGED:-0} |

          <details>
          <summary>‚è±Ô∏è Performance</summary>

          | Step | Duration |
          |------|----------|
          | Linking | ${LINK_STEP_DURATION:-N/A}s |
          | Commit | ${COMMIT_DURATION:-N/A}s |
          | **Total** | **${TOTAL_DURATION}s** |

          </details>

          ---
          *Completed at $(date -u +%Y-%m-%dT%H:%M:%SZ)*
          EOF

          echo "::notice::workflow=link docs=${LINK_DOCUMENTS_LINKED:-0} resolutions=${LINK_RESOLUTIONS:-0} proposals=${LINK_PROPOSALS:-0} duration=${TOTAL_DURATION}s"
